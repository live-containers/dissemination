\chapter{Introduction} \label{chap:introduction}

Containers have become the \textit{de-facto} alternative for managing application's life cycle in the cloud.
With the progressive shift from bare-metal, to virtualized servers, and now with containerization, cloud tenants aim to find the balance between optimal resource usage and quality of service (QoS) perceived by the user.
A key aspect to achieving a good QoS is the ability to manage resources efficiently, in particular load-balancing.
Having the ability to manage workloads efficiently, cloud providers can provide high-priority tasks the resources they demand, and starve less important ones until other resources become available.
Additionally, sharing and managing physical resources utilization, in particular ensuring that there are no severe imbalance among computing nodes, yet only the necessary ones are not idle, has a direct impact on energy savings for the data center.
The virtual machine (VM) placement problem~\cite{Masdari2016,Strunk2012} has studied this same issue for decades, the appearance of containers includes yet another variable to the optimization task. 

Checkpoint-Restore is, through live migration, a technique to provide application-level load-balancing capabilities to cloud tenants transparently to the user.
By dumping the state of an application and restoring it in another physical instance, it will resume from the exact point it was dumped at.
As a consequence, the user will perceive a minimal downtime and the tenant will have re-allocated resources.
Originally developed for the High Performance Computing (HPC) domain, checkpointing was used to save intermediate long-running job's state.
In the event of an unexpected failure, the job could be restarted from the last stored checkpoint, rather than restart and effectively lose several hours or days worth of work~\cite{Barker2014}.
Checkpoint-Restore in Userspace (CRIU)~\cite{criu-main-page} is a software tool to dump and restore processes transparently to the user.
It does so entirely from userspace, by strongly leveraging interfaces exposed by the Linux kernel.
If such interfaces do not exist, the project's contributors have a long history of accepted kernel patches~\cite{criu-kernel-patches}.
\criu is an open-source project and it targets specially applications running inside containers.
As of June 2020, most container engines offering checkpoint-restore functionalities such as \textsc{Docker}, \textsc{Podman}, or \textsc{LXC}, rely on \criu at a lower level.
In the cloud-computing and load-balancing domain, the project is used in a variety of companies such as Google~\cite{Tucker18} within their Borg project~\cite{Verma2015}.

This Master thesis is an initial approach to efficient transparent live migration of container deployments from userspace using \criu.
We study the different tools to checkpoint and restore containers and their integration with different container engines.
Then, we provide a library implementing live migration of running and connected containers transparently to the end user using \criu and \runc~\cite{introducing-runc} as our container runtime of choice.
Our implementation is very easy to use, has minimal dependencies, requires minimal set up, and differs from other existing solutions~\cite{phaul-github} in the fact that no listening process needs to be running in the remote end.
We support diskless, iterative (pre-copy) migration of memory intensive containers with established TCP connections and external namespaces.
Moreover, we back all of our design choices with an extensive evaluation in the form of micro and macro benchmarks and a comparison with traditional virtual machine migration.
Our system is open-source, still under development, and available at \url{https://github.com/live-containers/live-migration}.

\section{Objectives, Tasks, and Contributions}

The main goal of this work is to implement efficient live migration of running containers.
The terms \textit{efficient} and \textit{live} are vague in the absence of concise metrics, and the variety of running containers is also huge, as a consequence we specify a set of objectives we want our system to fulfill.
In particular, our key metric of success is downtime.
Downtime measures for how long a migrated application is not running, and as a consequence it is a direct indicator of liveness.
Additionally, we measure efficiency as the (lack of) redundancy and overhead our system introduces, usually in terms of allocated (and duplicated) memory and disk usage.
We evaluate it on absolute terms, and also relatively when compared with virtual machine migration and native (manual) container migration.
Our main objectives for the project can be summarized in the following list:
\begin{itemize}
    \item[\textbf{O1}] Implement a fully-featured live migration library for containers.
    \item[\textbf{O2}] Support memory-intensive server-oriented containers.
    \item[\textbf{O3}] Have live migration be: efficient, live, transparent, and easy to use.
\end{itemize}

In order to achieve \textbf{O1}, \textbf{O2}, and \textbf{O3}, we define a series of tasks our implementation presented in \S\ref{chap:system} must fulfil.
Note that these objectives and tasks are only implementation-oriented.
Part of the contribution of this work is also bibliographical in the sense that we cover all the relevant material that helps us in the process of achieving the objectives.
These non-tangible tasks and objectives are included in the final list of contributions.
\begin{itemize}
    \item[\textbf{T1}] Implement support to migrate interactive, memory-intensive, containers.
    \item[\textbf{T2}] Implement support to migrate containers with established TCP connections and external namespaces.
    \item[\textbf{T3}] Minimize downtime and resource utilization by using diskless and iterative migration techniques.
    \item[\textbf{T4}] Motivate each of our design choices with detailed micro-benchmarks to ensure we are aligned with \textbf{O3}.
\end{itemize}

\textbf{Contributions}

To put it in a nutshell, the main contributions of the work here presented are listed beneath:
\begin{itemize}
    \item[\textbf{C1}] An exhaustive micro-benchmark of different \criu features, their performance, and their integration with \runc.
    \item[\textbf{C2}] An open-source library for live migration of \runc containers using \criu.
    \item[\textbf{C3}] An easy to use binary to transparently migrate containers from one host to another with minimal dependencies and set up.
    \item[\textbf{C4}] An evaluation of our solution and a comparison with virtual machine migration.
\end{itemize}

\section{Project Structure}

The structure of the rest of this document is as follows.
In Chapter~\ref{chap:background} we introduce the foundational background concepts required to understand our contributions.
We do a deep dive in the topics of containers (\S\ref{sec:containers}), checkpointing (\S\ref{sec:bg-cp}), and \criu in particular (\S\ref{sec:bg-criu}).
Note that \runc is covered in detail when discussing different container engines and container runtimes.

In Chapter~\ref{chap:related-work}, we cover relevant bibliography and related work.
As the goal of a Master's thesis is educational in nature, we have decided to include not only other scientific contributions related to container checkpointing and live container migration, but also all the bibliographical material that we have used.
These references are both informative and educational, and will enable an interested reader to follow our same learning process which, in a document of this sort, is not to be underestimated.
In particular, we cover relevant bibliography on containers (\S\ref{sec:rw-cont}), \criu and C/R (\S\ref{sec:rw-criu}), and applications in live migration (\S\ref{sec:rw-app}).

In Chapter~\ref{chap:system} we present the building blocks of our system (\S\ref{sec:arch-blocks}): diskless migration, iterative migration, and TCP sockets and namespace migration.
For each concept, we present it's underlying theory together with a shell script to leverage it, it's implementation details in \criu, and the integration with \runc.
Additionally, we micro-benchmark it's functionality comparing the vanilla performance with \criu's and \runc's.
Then, in~\S\ref{sec:system} we cover in detail the implementation details of our solution, covering the most relevant code snippets, motivating our design choices (mostly with results from the previous section) and covering some helper modules we also implemented.

In Chapter~\ref{chap:evaluation} we put our system to work and, instead of micro-benchmarking particular features, we evaluate it as a whole through two different macro-benchmarks.
First, in~\S\ref{sec:eval-downtime}, we assess the impact different design choices have on the overall application downtime.
Downtime is the key metric in live migration as it assesses the time the application is not running.
Minimizing it is, in turn, the ultimate goal of efficient live migration.
Secondly, in~\S\ref{sec:eval-memory}, we measure our system's scalability with regard to the memory allocated by the container.
If downtime is the key metric to optimize, memory dumps and network latency are the two biggest bottlenecks.
Efficient network transport is out of the scope for this project, hence in this second macro-benchmark we focus on the efficiency of memory dumps.

Lastly, in Chapter~\ref{chap:conclusion}, we cover the most relevant conclusions and lessons learnt from the project, together with future lines of work we would like to continue in the coming months.
